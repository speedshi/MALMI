#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jul 22 16:45:23 2021

@author: Peidong SHI
@email: speedshi@hotmail.com
"""


import os
import h5py
import datetime
import numpy as np
from ioformatting import vector2trace
import copy
import gc


def eqt_arrayeventdetect(dir_probinput, dir_output, sttd_max, twlex, d_thrd, nsta_thrd=3, spttdf_ssmax=None):
    """
    This function is used to detect potential locatable events using the probabilities 
    generated by EQ-transformer from the whole array. The detection probability, 
    P-phase probability, S-phase probability of the detected event segments are 
    output to MSEED format in the output directory.
    
    Parameters
    ----------
    dir_probinput : str
        path to the EQT probability data set of different stations.
    dir_output : str
        path for data outputs.
    sttd_max : float
        maximum P-P traveltime difference between different stations for 
        the whole imaging area, in second.
    twlex : float
        time in second for extending the time window, roughly equal to the 
        width of P- or S-probability envelope. Value ranges from 0.5-2 second.
    d_thrd : float
        detection threshold. The threshold value depends on the performance of 
        the machine learning model. Use a low threshold to detect more weak events,
        but could also increase false positives. Use a high threshold to detect
        events with more confidance, but could miss some weak or usual events.
        Since we will perform migration on phase probabilities to image and 
        locate the souces, we are using spatial coherency accross the whole array.
        So it is suggestted to use a relatively low threshold for detection, 
        and migration process can later take care of event location and 
        potentially remove false positives by additional event selection process
        later. For EQT, suggestted threshold values from 0.05 - 0.5
    nsta_thrd : int, optional
        minimal number of stations triggered during a specified time period, 
        If there are more triggered stations than this threshold, the algrithem
        determines there is an event in the current searched time period, then
        it will start to ouput probapility data of different stations to the 
        defined output directory. Each event will have a unique folder name 
        according to the starttime of its data segment.
        The default is 3.
    spttdf_ssmax: float, optional
        the maximal P to S arrivaltime difference for a perticular station in 
        second for the imaging area. No need to be very accurate.

    Returns
    -------
    Obspy trace data outputted in MSEED format in the defined output directory.

    """

    if spttdf_ssmax is None:
        spttdf_ssmax = 0.5*sttd_max


    # internal parameters
    pbfname = 'prediction_probabilities.hdf5'  # the common filename of probability file for each station
    dtformat_EQT = '%Y-%m-%dT%H:%M:%S.%fZ'  # the datetime format using in EQT probability hdf5 outputs
    data_size_EQT = 6000  # the data segment size in date points, by default the EQT output are 1 minutes long, thus 6000 points
    dt_EQT = 0.01  # time sampling rate of data in second, for EQT probability output, by default is 0.01 s
    data_sglength = (data_size_EQT-1)*dt_EQT  # data segment length in second, equals 'endtime - starttime'
    N_tit = 1  # number of iteration for settle the starttime and endtime of data segment; should be 1, 2, 3; set 1 for fast calculation, set 2 or 3 if want to obtain better time constrain
    
    datainfo = {}
    datainfo['dt'] = dt_EQT
    
    
    # load timing info and the detection probability
    # obtain the folder name for the results of each station, each folder contain the probability data of one station
    db = {}  # for storing the whole data set: timestamp info + detection probability
    stanames = []
    dirnames = sorted([fdname for fdname in os.listdir(dir_probinput) if os.path.isdir(os.path.join(dir_probinput, fdname))])
    dsg_sttmin = None  # earliest starttime of data segment
    dsg_sttmax = None  # latest endtime of data segment
    for sfdname in dirnames:
        # loop over each station folder, read data set for each station
        station_name = sfdname.split('_')[0]  # the current station name
        pbfile = os.path.join(dir_probinput, sfdname, pbfname)  # the filename of picking probability for the current station
        
        # load probability data set
        pbdf = h5py.File(pbfile, 'r')
        dsg_name = list(pbdf['probabilities'].keys())  # get the name of each probability data segment 
        dsg_starttime = np.array([datetime.datetime.strptime(idsgnm.split('_')[-1], dtformat_EQT) for idsgnm in dsg_name])  # get the starttime of each probability data segment 
        dsg_endtime = np.array([iitime + datetime.timedelta(seconds=data_sglength) for iitime in dsg_starttime])  # get the endtime of each probability data segment 
    
        # find the minimal starttime and maximum endtime of all data segments over all stations
        if dsg_sttmin:
            dsg_sttmin = min(dsg_sttmin, min(dsg_starttime))
        else:
            dsg_sttmin = min(dsg_starttime)
        if dsg_sttmax:
            dsg_sttmax = max(dsg_sttmax, max(dsg_endtime))
        else:
            dsg_sttmax = max(dsg_endtime)
        
        prob_D = []
        for idsg in dsg_name:
            pbdata = np.zeros((data_size_EQT, 3), dtype=np.float32)  # initialize array for load prob data set
            pbdf['probabilities'][idsg].read_direct(pbdata)  # EQT probability data set, shape: 6000*3
            prob_D.append(pbdata[:,0])  # detection probability
            del pbdata
            
        db[station_name] = [dsg_starttime, dsg_endtime, prob_D, dsg_name]  # starting datetime of each data segement and the corresponding detection probability
        stanames.append(station_name)  # all avaliable station names
            
        del station_name, pbfile, pbdf, dsg_name, dsg_starttime, dsg_endtime, prob_D
        
    
    # scan data from 'dsg_sttmin' to 'dsg_sttmax' to search for all potential events/triggers
    # tt1 : the starttime of searched time range
    # tt2 : the endtime of searched time range
    # tts : the starttime of data extraction
    # ttd : the endtime for data extraction, ttd <= tt2
    # tts_sta : the starttime for a probability data segment above threshold at different stations
    # ttd_sta : the endtime for a probability data segment above threshold at different stations
    tt1 = copy.deepcopy(dsg_sttmin)
    ttd_previous = copy.deepcopy(dsg_sttmin)  # the endtime of data extraction for the previous data output
    while tt1 <= dsg_sttmax:
        # Find if there are enough stations have detection values above the 
        # threshold (triggered) at the searched time range. 
        # If yes, then find a event and output data.
        
        # set the endtime for searched time range
        tt2 = tt1 + datetime.timedelta(seconds=(sttd_max+twlex))  # use 'maximum P2S traveltime difference' + 'extend window length' to set the endtime of searching time range
        # make sure tt2 does not exceed the maximum time
        if tt2 > dsg_sttmax:
            tt2 = copy.deepcopy(dsg_sttmax)
        
        for itit in range(N_tit):
            
            if itit > 0:
                tt1 = copy.deepcopy(tts)
                tt2 = copy.deepcopy(ttd)
            
            # initialize parameters
            tts = None
            ttd = None
            tts_sta = {}
            ttd_sta = {}
            nsta_trig = 0  # number of stations triggered
            
            for sta in stanames:
                # loop over each station
                
                # flag to indicate if the current station has already been triggered or not
                station_triggered = False
                
                # maximum detection probability for the current event in the searched time period
                prob_det_max = 0.0
                
                # find all data segments which contain the whole searched time period
                dindx = np.logical_and((db[sta][0] <= tt1), (db[sta][1] >= tt2))  # the index of data segments that include the whole searched time period
                if dindx.any():
                    for isgindex in np.flatnonzero(dindx):
                        # loop over each fulfilled data segment, find the earliest 'tts' and the latest 'ttd'
                        
                        data_sgindex = copy.deepcopy(isgindex)  # the index of the chosen data segment, is an integer
                        data_starttime = db[sta][0][data_sgindex]  # starttime of the chosen data segment
                        data_times = np.array([data_starttime + datetime.timedelta(seconds=iitp*dt_EQT) for iitp in range(data_size_EQT)])  # timestampe of each data point
                        data_probD = db[sta][2][data_sgindex]  # detection probability of the chosen data segment
                        
                        data_pdindex = np.logical_and((data_times >= tt1), (data_times <= tt2))  # the index of probability data point within the detection time range
                        detecid = (data_probD[data_pdindex] >= d_thrd)  # boolen array to indicate whether there are detections above threshold
                        
                        if detecid.any():
                            # have detetion at the current station and the searched time period
                            
                            # determine if this station has been triggered and update the accumulated number
                            if not station_triggered:
                                nsta_trig = nsta_trig + 1  
                                station_triggered = True
                        
                            idfirst = np.flatnonzero(data_pdindex)[0]  # the index of the first point in the searched time period
                            idlast = np.flatnonzero(data_pdindex)[-1]  # the index of the last point in the searched time period
                            
                            # set tts, and update tt2
                            if (data_probD[idfirst] >= d_thrd) and (idfirst > 0) and (data_probD[idfirst-1] >= d_thrd):
                                # starttime and the data point just before the starttime are both above threshold
                                ddinx = np.flatnonzero(data_probD[0:idfirst] < d_thrd)  
                                if ddinx.size > 0:
                                    # get the last occurance for the prior points with a detection value smaller than threshold
                                    tts_temp = data_times[ddinx[-1] + 1] - datetime.timedelta(seconds=twlex)
                                else:
                                    # all the prior data points exceed detection threshold
                                    tts_temp = data_times[0] - datetime.timedelta(seconds=spttdf_ssmax)  # note move the starttime ahead 
                                    
                                del ddinx
                            elif (data_probD[idfirst] >= d_thrd) and (idfirst == 0):
                                # starttime is above the threshold and also is the first point of this segment
                                tts_temp = data_times[0] - datetime.timedelta(seconds=spttdf_ssmax)  # note move the starttime ahead
                            else:
                                # the starttime tt1 has detetion probability below threshold
                                tts_temp = data_times[idfirst + np.argmax(detecid)] - datetime.timedelta(seconds=twlex)
                            
                            # set tts_sta for the current station
                            dprobD_max = max(data_probD[data_pdindex])  # maximum detection probability for the current time segment and station
                            if (dprobD_max > prob_det_max):
                                tts_sta[sta] = copy.deepcopy(tts_temp)
                            # if sta in tts_sta:
                            #     tts_sta[sta] = min(tts_sta[sta], tts_temp)
                            # else:
                            #     tts_sta[sta] = copy.deepcopy(tts_temp)
                            if tts_sta[sta] < ttd_previous:
                                tts_sta[sta] = copy.deepcopy(ttd_previous)
                            
                            # set tts
                            if tts:
                                tts = min(tts, tts_sta[sta])  # tts = min(tts, tts_temp)
                            else:
                                tts = copy.deepcopy(tts_sta[sta])  # tts = copy.deepcopy(tts_temp)
                            # make sure the 'tts' is not earlier than the endtime of the previous data extraction
                            if tts < ttd_previous:
                                tts = copy.deepcopy(ttd_previous)
                            
                            # set tt2
                            if tts > tt1:
                                tt2 = tts + datetime.timedelta(seconds=(sttd_max+twlex))
                            else:
                                tt2 = tt1 + datetime.timedelta(seconds=(sttd_max+twlex))
                            if tt2 > dsg_sttmax:
                                tt2 = copy.deepcopy(dsg_sttmax)
                            
                            del tts_temp
                            
                            # set ttd, and update tt2
                            if (data_probD[idlast] >= d_thrd) and (idlast < data_size_EQT-1) and (data_probD[idlast+1] >= d_thrd):
                                # endtime and the next point of endtime are both above threshold
                                ddinx = np.argmax(data_probD[idlast+1:] < d_thrd)  # first occurance for the remaining points with a detection value smaller than threshold
                                if ddinx > 0:
                                    # the remaining data points have detection value below threshold
                                    ttd_temp = data_times[idlast + ddinx] + datetime.timedelta(seconds=twlex)
                                else:
                                    # all the remaining data points exceed detection threshold
                                    ttd_temp = data_times[-1] + datetime.timedelta(seconds=spttdf_ssmax)  # note move the endtime after
                                    
                                del ddinx
                            elif (data_probD[idlast] >= d_thrd) and (idlast == data_size_EQT-1):
                                # endtime is above the threshold and also is the last point of this segment
                                ttd_temp = data_times[-1] + datetime.timedelta(seconds=spttdf_ssmax)  # note move the endtime after
                            else:
                                # the next point after endtime is below threshold,
                                # or just before or at the endtime is below threshold. 
                                ttd_temp = data_times[idfirst + np.flatnonzero(detecid)[-1]] + datetime.timedelta(seconds=twlex)
                            
                            # set ttd_sta for the current station
                            if (dprobD_max > prob_det_max):
                                ttd_sta[sta] = copy.deepcopy(ttd_temp)
                                prob_det_max = copy.deepcopy(dprobD_max)
                            # if sta in ttd_sta:
                            #     ttd_sta[sta] = max(ttd_sta[sta], ttd_temp)
                            # else:
                            #     ttd_sta[sta] = copy.deepcopy(ttd_temp)
                            if ttd_sta[sta] > dsg_sttmax:
                                ttd_sta[sta] = copy.deepcopy(dsg_sttmax)
                            
                            # set ttd
                            if ttd:
                                ttd = max(ttd, ttd_sta[sta])  # ttd = max(ttd, ttd_temp)
                            else: 
                                ttd = copy.deepcopy(ttd_sta[sta])  # ttd = copy.deepcopy(ttd_temp)
                            if ttd > dsg_sttmax:
                                ttd = copy.deepcopy(dsg_sttmax)
                            
                            # set tt2
                            tt2 = max(tt2, ttd)
                            if tt2 > dsg_sttmax:
                                tt2 = copy.deepcopy(dsg_sttmax)    
                            
                            del idfirst, idlast, ttd_temp, dprobD_max
                            
                        # clear memory
                        del data_sgindex, data_starttime, data_times, data_probD, data_pdindex, detecid
                    del isgindex
                del dindx, prob_det_max
        
            if (nsta_trig < nsta_thrd):
                break
        
        # write P- and S-phase probability data for the current searched time period
        # if there are more triggered stations than the threshold (3 stations)
        # output data from time range: 'tts' to 'ttd'
        if (nsta_trig >= nsta_thrd):
            # print info
            print('----------------------------------------------------------')
            print('Detect event at time range:', tts, '-', ttd)
            print(nsta_trig, 'stations are triggered.')
            print('Start to output data in this time range.')
            
            # after the previous loop over all stations, the 'tt1', 'tt2', 'tts', 'ttd', 'tts_sta', 'ttd_sta' are now fixed
            dir_output_ev = dir_output + '/' + tts.strftime(dtformat_EQT)  # output directory for the current event/time_range
            
            for sta in stanames:
                # loop over each station, check data, and load P S probability, and output avaliable data set
                
                # set the midpoint time for the current station
                if sta in tts_sta:
                    # set the midpoint time between the starttime and endtime tailored for the current station
                    tt_mid =  tts_sta[sta] + (ttd_sta[sta] - tts_sta[sta])/2 
                else:
                    # no detection for the current station
                    # set the midpoint between the starttime and endtime of data extraction
                    tt_mid =  tts + (ttd - tts)/2  
                
                dindx = np.logical_and((db[sta][0] <= tts), (db[sta][1] >= ttd))  # the index of data segments that include the whole searched time period
                if dindx.any():
                    # have data segments that fulfill the requirements
                    # find the data segment where the searched time period is mostly around the center
                    mdtimesdf = np.array([ttdfc.total_seconds() for ttdfc in db[sta][0][dindx] + datetime.timedelta(seconds=0.5*data_sglength) - tt_mid])  # time difference in second between the midpoint of the fulfilled data segments time range and the searched time period
                    data_sgindex = np.flatnonzero(dindx)[np.argmin(abs(mdtimesdf))]  # the index of the chosen data segment, is an integer
                    data_sgname = db[sta][3][data_sgindex]  # the segment name of the chosen data segment
                    data_starttime = db[sta][0][data_sgindex]  # starttime of the chosen data segment
                    data_times = np.array([data_starttime + datetime.timedelta(seconds=iitp*dt_EQT) for iitp in range(data_size_EQT)])  # timestampe of each data point for the chosen data segment
                    data_pdindex = np.logical_and((data_times >= tts), (data_times <= ttd))  # the index of probability data point within the detection time range
                    odata_time = data_times[data_pdindex]  # the timestampe of outout data
                    
                    # set data info               
                    datainfo['station_name'] = sta
                    datainfo['starttime'] = odata_time[0]  # the starttime of the output data
                    
                    # load data set: Detetion, P and S probability
                    pbfile = os.path.join(dir_probinput, sta+'_outputs', pbfname)  # the filename of picking probability for the current station
                    pbdf = h5py.File(pbfile, 'r')
                    pbdata = np.zeros((data_size_EQT, 3), dtype=np.float32)  # initialize array for load prob data set
                    pbdf['probabilities'][data_sgname].read_direct(pbdata)  # EQT probability data set, shape: 6000*3
                    oprob_D = pbdata[data_pdindex,0]  # detection probability
                    oprob_P = pbdata[data_pdindex,1]  # P-phase picking probability
                    oprob_S = pbdata[data_pdindex,2]  # S-phase picking probability
                                    
                    # output detection probability
                    datainfo['channel_name'] = 'PBD'  # note maximum three characters, the last one must be 'D'
                    vector2trace(datainfo, oprob_D, dir_output_ev)
                    
                    # output P-phase picking probability
                    datainfo['channel_name'] = 'PBP'  # note maximum three characters, the last one must be 'P'
                    vector2trace(datainfo, oprob_P, dir_output_ev)
                    
                    # output S-phase picking probability
                    datainfo['channel_name'] = 'PBS'  # note maximum three characters, the last one must be 'S'
                    vector2trace(datainfo, oprob_S, dir_output_ev)
                    
                    # clear memory
                    del mdtimesdf, data_sgindex, data_sgname, data_starttime, data_times, data_pdindex, odata_time
                    del pbfile, pbdf, pbdata, oprob_D, oprob_P, oprob_S
                
                del dindx
            del tt_mid, dir_output_ev
        
            # updata 'ttd_previous'
            ttd_previous = copy.deepcopy(ttd)
        
        # update the starttime for detection
        if ttd:
            tt1 = ttd + datetime.timedelta(seconds=dt_EQT)
        else:
            tt1 = tt2 + datetime.timedelta(seconds=dt_EQT)

        del tts_sta, ttd_sta, tts, ttd, nsta_trig
    gc.collect()    
    return    
        
        
def eqt_eventdetectfprob(dir_probinput, P_thrd, S_thrd):
    """
    This function is used to detect potential events using the phase probabilities 
    generated by EQ-transformer for each station. Phase probabilies (including P and S) 
    above the input threshold are viewed as potential events. Detection is performed 
    individually on each station.
    
    Parameters
    ----------
    dir_probinput : str
        path to the EQT probability data set of different stations.
    P_thrd : float
        detection threshold for P-phase. The threshold value depends on the performance of 
        the machine learning model. Use a low threshold to detect more weak events,
        but could also increase false positives. Use a high threshold to detect
        events with more confidance, but could miss some weak or usual events.
        Since we will perform migration on phase probabilities to image and 
        locate the souces, we are using spatial coherency accross the whole array.
        So it is suggestted to use a relatively low threshold for detection, 
        and migration process can later take care of event location and 
        potentially remove false positives by additional event selection process
        later. For EQT, suggestted threshold values from 0.05 - 0.5
    S_thrd : float
        detection threshold for S-phase. When S-phase probabilities are larger
        than this threshold value, a event will be detected.  

    Returns
    -------
    event_info : dictionary
        containing the detected event information at each station;
        event_info[station_name][filename]: str indicating the filename of probability 
                                            dataset for the current station;
        event_info[station_name][p][starttime]: a list of datetime indicating the 
                                                starttime of each event detected 
                                                on the P-phase probability;
        event_info[station_name][P][endtime]: a list of datetime indicating the 
                                              endtime of each event detected 
                                              on the P-phase probability;
        event_info[station_name][P][mxptime]: a list of datetime indicating the 
                                              maximum probability time of each event 
                                              detected on the P-phase probability,
                                              is the picked arrivaltime for P-phase;
        event_info[station_name][P][maxprob]: a list of float indicating the maximum
                                              P-phase probability between P-starttime
                                              and P-endtime of each detected event;
        event_info[station_name][P][sgname]: a list of str indicating the P-probability
                                             data segment name for extracting maxprob;                              
        event_info[station_name][S][starttime]: a list of datetime indicating the 
                                                starttime of each event detected 
                                                on the S-phase probability;
        event_info[station_name][S][endtime]: a list of datetime indicating the 
                                              endtime of each event detected 
                                              on the S-phase probability;
        event_info[station_name][S][mxptime]: a list of datetime indicating the 
                                              maximum probability time of each event 
                                              detected on the S-phase probability,
                                              is the picked arrivaltime for S-phase;
        event_info[station_name][S][maxprob]: a list of float indicating the maximum
                                              S-phase probability between S-starttime
                                              and S-endtime of each detected event;
        event_info[station_name][S][sgname]: a list of str indicating the S-probability
                                             data segment name for extracting maxprob; 

    """

    # internal parameters for EQT
    pbfname = 'prediction_probabilities.hdf5'  # the common filename of probability file for each station
    dtformat_EQT = '%Y-%m-%dT%H:%M:%S.%fZ'  # the datetime format using in EQT probability hdf5 outputs
    data_size_EQT = 6000  # the data segment size in date points, by default the EQT output are 1 minutes long, thus 6000 points
    dt_EQT = 0.01  # time sampling rate of data in second, for EQT probability output, by default is 0.01 s
    data_sglength = (data_size_EQT-1)*dt_EQT  # data segment length in second, equals 'endtime - starttime' 
    
    event_info = {}  # initialize
    
    # obtain the folder name for the results of each station, each folder contain the probability data of one station
    dirnames = sorted([fdname for fdname in os.listdir(dir_probinput) if os.path.isdir(os.path.join(dir_probinput, fdname))])  # directory names for each station
    for sfdname in dirnames:
        # loop over each station folder, read data set for each station
        station_name = sfdname.split('_')[0]  # the current station name
        pbfile = os.path.join(dir_probinput, sfdname, pbfname)  # the filename of picking probability for the current station
        
        # initialize
        event_info[station_name] = {}
        event_info[station_name]['filename'] = copy.deepcopy(pbfile)  # record the filename of the probability dataset
        event_info[station_name]['P'] = {}
        event_info[station_name]['P']['starttime'] = []
        event_info[station_name]['P']['endtime'] = []
        event_info[station_name]['P']['mxptime'] = []
        event_info[station_name]['P']['maxprob'] = []
        event_info[station_name]['P']['sgname'] = []
        event_info[station_name]['S'] = {}
        event_info[station_name]['S']['starttime'] = []
        event_info[station_name]['S']['endtime'] = []
        event_info[station_name]['S']['mxptime'] = []
        event_info[station_name]['S']['maxprob'] = []
        event_info[station_name]['S']['sgname'] = []
        
        # load probability data set and the timing information
        pbdf = h5py.File(pbfile, 'r')
        dsg_name = list(pbdf['probabilities'].keys())  # get the names of all probability data segments 
        dsg_starttime = np.array([datetime.datetime.strptime(idsgnm.split('_')[-1], dtformat_EQT) for idsgnm in dsg_name])  # get the starttimes of all probability data segments 
        dsg_endtime = np.array([iitime + datetime.timedelta(seconds=data_sglength) for iitime in dsg_starttime])  # get the endtimes of all probability data segments
        
        for ii, idsg in enumerate(dsg_name):
            # loop over each data segment
            pbdata = np.zeros((data_size_EQT, 3), dtype=np.float32)  # initialize an array for loading prob data set
            pbdf['probabilities'][idsg].read_direct(pbdata)  # EQT probability data set, shape: 6000*3, colume 0: event_prob; colume 1: P_prob; colume 2: S_prob
            pbtime = [dsg_starttime[ii] + datetime.timedelta(seconds=ipoint*dt_EQT) for ipoint in range(data_size_EQT)]  # datetime of each data point
            
            # perform detection based on P-phase probabilites: pbdata[:,1]
            epindx = np.flatnonzero((pbdata[:,1] >= P_thrd))  # the indices of all data points with probability larger than threshold
            for iep in epindx:
                if (iep == 0) or ((iep-1) not in epindx):
                    # current time is the starttime
                    temp_startime = copy.deepcopy(pbtime[iep])  # get the starttime of the detected event
                    start_did = copy.deepcopy(iep)  # the data index of the starting point of the detected event
                if (iep == (data_size_EQT-1)) or ((iep+1) not in epindx):
                    # current time is the endtime
                    temp_endtime = copy.deepcopy(pbtime[iep])  # get the endtime of the detected event
                    end_did = copy.deepcopy(iep)  # the data index of the ending point of the detected event
                    temp_maxprob = max(pbdata[start_did:end_did+1,1])  # get the maximum probability of the detected event
                    temp_mxptime = pbtime[start_did + np.argmax(pbdata[start_did:end_did+1,1])]  # get the maximum probability time of the detected event, i.e. phase-picking time
                    assert((temp_mxptime >= temp_startime) and (temp_mxptime <= temp_endtime))
                                   
                    # compare with the existing detected events
                    if event_info[station_name]['P']['starttime']:
                        # there are existing events in the event list
                        # check with existing events, get the index of the events that need to update info
                        
                        # situation when need to update starttime of one event
                        # maximum only one event need to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-----------++++++++++++-------------|
                        evid_s = np.flatnonzero((np.array(event_info[station_name]['P']['starttime']) > temp_startime)
                                                & (np.array(event_info[station_name]['P']['starttime']) <= temp_endtime)
                                                & (np.array(event_info[station_name]['P']['endtime']) >= temp_endtime))
                        assert(len(evid_s) <= 1), "More than one event to only update starttime. Impossible. There must be errors!"
                        
                        # situation when need to update endtime of one event
                        # maximum only one event need to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-------------+++++++++++------------|
                        evid_e = np.flatnonzero((np.array(event_info[station_name]['P']['starttime']) <= temp_startime) 
                                                & (np.array(event_info[station_name]['P']['endtime']) >= temp_startime)
                                                & (np.array(event_info[station_name]['P']['endtime']) < temp_endtime))
                        assert(len(evid_e) <= 1), "More than one event to only update endtime. Impossible. There must be errors!"
                        
                        # situation when need to update both starttime and endtime
                        # might be more than one event to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-----------+++++++++++++------------|
                        evid_se = np.flatnonzero((np.array(event_info[station_name]['P']['starttime']) > temp_startime) 
                                                 & (np.array(event_info[station_name]['P']['endtime']) < temp_endtime))
                        
                        # situation when detected event time range is within the time range of one event
                        # no need to update starttime and endtime, but need to check if update 'maxprob' and 'sgname'
                        # maximum only one event need to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-------------++++++++++-------------|
                        evid_in = np.flatnonzero((np.array(event_info[station_name]['P']['starttime']) <= temp_startime) 
                                                 & (np.array(event_info[station_name]['P']['endtime']) >= temp_endtime))
                        assert(len(evid_in) <= 1), "More than one event containing the detected event. Impossible. There must be errors!"
                        
                        if (len(evid_in) == 1):
                            # the detected event starttime and endtime are within the starttime and endtime of one event in the list
                            # no need to update starttime and endtime, but need to check if update 'maxprob' and 'sgname'
                            assert(len(evid_s)==0 and len(evid_e)==0 and len(evid_se)==0)
                            if event_info[station_name]['P']['maxprob'][evid_in[0]] < temp_maxprob:
                                # need to update 'maxprob', 'mxptime' and 'sgname'
                                event_info[station_name]['P']['maxprob'][evid_in[0]] = copy.deepcopy(temp_maxprob)
                                event_info[station_name]['P']['mxptime'][evid_in[0]] = copy.deepcopy(temp_mxptime)
                                event_info[station_name]['P']['sgname'][evid_in[0]] = copy.deepcopy(idsg)
                                
                        elif (len(evid_s) + len(evid_e) + len(evid_se) == 1):
                            # only one event in the event list need to update
                            assert(len(np.concatenate((evid_s, evid_e, evid_se))) == 1)
                            evid = np.concatenate((evid_s, evid_e, evid_se))[0]  # the index of the event to update
                            event_info[station_name]['P']['starttime'][evid] = copy.deepcopy(min(event_info[station_name]['P']['starttime'][evid], temp_startime))
                            event_info[station_name]['P']['endtime'][evid] = copy.deepcopy(max(event_info[station_name]['P']['endtime'][evid], temp_endtime))
                            if event_info[station_name]['P']['maxprob'][evid] < temp_maxprob:
                                event_info[station_name]['P']['maxprob'][evid] = copy.deepcopy(temp_maxprob)
                                event_info[station_name]['P']['mxptime'][evid] = copy.deepcopy(temp_mxptime)
                                event_info[station_name]['P']['sgname'][evid] = copy.deepcopy(idsg)
                            del evid
                            
                        elif (len(evid_s) + len(evid_e) + len(evid_se) > 1):
                            # more than one event in the event list are overlaping with the detected event
                            # update the first event to include all, and remove the other events from event list
                            evid = np.sort(np.concatenate((evid_s, evid_e, evid_se)))  # the sorted index array of the events which show overlaping times with the detected event
                            assert(len(evid) > 1)
                            event_info[station_name]['P']['starttime'][evid[0]] = copy.deepcopy(min(np.min(np.array(event_info[station_name]['P']['starttime'])[evid]), temp_startime))
                            event_info[station_name]['P']['endtime'][evid[0]] = copy.deepcopy(max(np.max(np.array(event_info[station_name]['P']['endtime'])[evid]), temp_endtime))
                            xxid = np.argmax(np.array(event_info[station_name]['P']['maxprob'])[evid])
                            if event_info[station_name]['P']['maxprob'][evid[xxid]] < temp_maxprob:
                                event_info[station_name]['P']['maxprob'][evid[0]] = copy.deepcopy(temp_maxprob)
                                event_info[station_name]['P']['mxptime'][evid[0]] = copy.deepcopy(temp_mxptime)
                                event_info[station_name]['P']['sgname'][evid[0]] = copy.deepcopy(idsg)
                            else:
                                event_info[station_name]['P']['maxprob'][evid[0]] = copy.deepcopy(event_info[station_name]['P']['maxprob'][evid[xxid]])
                                event_info[station_name]['P']['mxptime'][evid[0]] = copy.deepcopy(event_info[station_name]['P']['mxptime'][evid[xxid]])
                                event_info[station_name]['P']['sgname'][evid[0]] = copy.deepcopy(event_info[station_name]['P']['sgname'][evid[xxid]])
                            for jjj in evid[-1:0:-1]:
                                # delete the other events
                                del event_info[station_name]['P']['starttime'][jjj]
                                del event_info[station_name]['P']['endtime'][jjj]
                                del event_info[station_name]['P']['maxprob'][jjj]
                                del event_info[station_name]['P']['mxptime'][jjj]
                                del event_info[station_name]['P']['sgname'][jjj]
                            del evid, xxid
                            
                        else:
                            # do not have time overlaping with any event, directly insert into the event list
                            assert(len(evid_s)==0 and len(evid_e)==0 and len(evid_se)==0 and len(evid_in) ==0)
                            insertid = np.flatnonzero(np.array(event_info[station_name]['P']['starttime']) > temp_startime)
                            if (len(insertid) > 0):
                                event_info[station_name]['P']['starttime'].insert(insertid[0], copy.deepcopy(temp_startime))
                                event_info[station_name]['P']['endtime'].insert(insertid[0], copy.deepcopy(temp_endtime))
                                event_info[station_name]['P']['maxprob'].insert(insertid[0], copy.deepcopy(temp_maxprob))
                                event_info[station_name]['P']['mxptime'].insert(insertid[0], copy.deepcopy(temp_mxptime))
                                event_info[station_name]['P']['sgname'].insert(insertid[0], copy.deepcopy(idsg))
                            else:
                                event_info[station_name]['P']['starttime'].append(copy.deepcopy(temp_startime))
                                event_info[station_name]['P']['endtime'].append(copy.deepcopy(temp_endtime))
                                event_info[station_name]['P']['maxprob'].append(copy.deepcopy(temp_maxprob))
                                event_info[station_name]['P']['mxptime'].append(copy.deepcopy(temp_mxptime))
                                event_info[station_name]['P']['sgname'].append(copy.deepcopy(idsg))
                            del insertid
                        del evid_s, evid_e, evid_se, evid_in
                    else:
                        # no detected events yet, append the detected event to the empty event list directly
                        event_info[station_name]['P']['starttime'].append(copy.deepcopy(temp_startime))
                        event_info[station_name]['P']['endtime'].append(copy.deepcopy(temp_endtime))
                        event_info[station_name]['P']['maxprob'].append(copy.deepcopy(temp_maxprob))
                        event_info[station_name]['P']['mxptime'].append(copy.deepcopy(temp_mxptime))
                        event_info[station_name]['P']['sgname'].append(copy.deepcopy(idsg))
                    
                    del temp_startime, temp_endtime, temp_maxprob, temp_mxptime, start_did, end_did
                    assert(event_info[station_name]['P']['mxptime'][-1] >= event_info[station_name]['P']['starttime'][-1])
                    assert(event_info[station_name]['P']['mxptime'][-1] <= event_info[station_name]['P']['endtime'][-1])
            del epindx
            
            # perform detection based on S-phase probabilites: pbdata[:,2]
            epindx = np.flatnonzero((pbdata[:,2] >= S_thrd))  # the indices of all data points with probability larger than threshold
            for iep in epindx:
                if (iep == 0) or ((iep-1) not in epindx):
                    # current time is the starttime
                    temp_startime = copy.deepcopy(pbtime[iep])  # get the starttime of the detected event
                    start_did = copy.deepcopy(iep)  # the data index of the starting point of the detected event
                if (iep == (data_size_EQT-1)) or ((iep+1) not in epindx):
                    # current time is the endtime
                    temp_endtime = copy.deepcopy(pbtime[iep])  # get the endtime of the detected event
                    end_did = copy.deepcopy(iep)  # the data index of the ending point of the detected event
                    temp_maxprob = max(pbdata[start_did:end_did+1,2])  # get the maximum probability of the detected event
                    temp_mxptime = pbtime[start_did + np.argmax(pbdata[start_did:end_did+1,2])]  # get the maximum probability time of the detected event, i.e. phase-picking time
                    assert((temp_mxptime >= temp_startime) and (temp_mxptime <= temp_endtime))
                                   
                    # compare with the existing detected events
                    if event_info[station_name]['S']['starttime']:
                        # there are existing events in the event list
                        # check with existing events, get the index of the events that need to update info
                        
                        # situation when need to update starttime of one event
                        # maximum only one event need to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-----------++++++++++++-------------|
                        evid_s = np.flatnonzero((np.array(event_info[station_name]['S']['starttime']) > temp_startime)
                                                & (np.array(event_info[station_name]['S']['starttime']) <= temp_endtime)
                                                & (np.array(event_info[station_name]['S']['endtime']) >= temp_endtime))
                        assert(len(evid_s) <= 1), "More than one event to only update starttime. Impossible. There must be errors!"
                        
                        # situation when need to update endtime of one event
                        # maximum only one event need to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-------------+++++++++++------------|
                        evid_e = np.flatnonzero((np.array(event_info[station_name]['S']['starttime']) <= temp_startime) 
                                                & (np.array(event_info[station_name]['S']['endtime']) >= temp_startime)
                                                & (np.array(event_info[station_name]['S']['endtime']) < temp_endtime))
                        assert(len(evid_e) <= 1), "More than one event to only update endtime. Impossible. There must be errors!"
                        
                        # situation when need to update both starttime and endtime
                        # might be more than one event to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-----------+++++++++++++------------|
                        evid_se = np.flatnonzero((np.array(event_info[station_name]['S']['starttime']) > temp_startime) 
                                                 & (np.array(event_info[station_name]['S']['endtime']) < temp_endtime))
                        
                        # situation when detected event time range is within the time range of one event
                        # no need to update starttime and endtime, but need to check if update 'maxprob' and 'sgname'
                        # maximum only one event need to update!
                        # exist: |-------------++++++++++-------------|
                        # temp : |-------------++++++++++-------------|
                        evid_in = np.flatnonzero((np.array(event_info[station_name]['S']['starttime']) <= temp_startime) 
                                                 & (np.array(event_info[station_name]['S']['endtime']) >= temp_endtime))
                        assert(len(evid_in) <= 1), "More than one event containing the detected event. Impossible. There must be errors!"
                        
                        if (len(evid_in) == 1):
                            # the detected event starttime and endtime are within the starttime and endtime of one event in the list
                            # no need to update starttime and endtime, but need to check if update 'maxprob' and 'sgname'
                            assert(len(evid_s)==0 and len(evid_e)==0 and len(evid_se)==0)
                            if event_info[station_name]['S']['maxprob'][evid_in[0]] < temp_maxprob:
                                # need to update 'maxprob', 'mxptime' and 'sgname'
                                event_info[station_name]['S']['maxprob'][evid_in[0]] = copy.deepcopy(temp_maxprob)
                                event_info[station_name]['S']['mxptime'][evid_in[0]] = copy.deepcopy(temp_mxptime)
                                event_info[station_name]['S']['sgname'][evid_in[0]] = copy.deepcopy(idsg)
                                
                        elif (len(evid_s) + len(evid_e) + len(evid_se) == 1):
                            # only one event in the event list need to update
                            assert(len(np.concatenate((evid_s, evid_e, evid_se))) == 1)
                            evid = np.concatenate((evid_s, evid_e, evid_se))[0]  # the index of the event to update
                            event_info[station_name]['S']['starttime'][evid] = copy.deepcopy(min(event_info[station_name]['S']['starttime'][evid], temp_startime))
                            event_info[station_name]['S']['endtime'][evid] = copy.deepcopy(max(event_info[station_name]['S']['endtime'][evid], temp_endtime))
                            if event_info[station_name]['S']['maxprob'][evid] < temp_maxprob:
                                event_info[station_name]['S']['maxprob'][evid] = copy.deepcopy(temp_maxprob)
                                event_info[station_name]['S']['mxptime'][evid] = copy.deepcopy(temp_mxptime)
                                event_info[station_name]['S']['sgname'][evid] = copy.deepcopy(idsg)
                            del evid
                            
                        elif (len(evid_s) + len(evid_e) + len(evid_se) > 1):
                            # more than one event in the event list are overlaping with the detected event
                            # update the first event to include all, and remove the other events from event list
                            evid = np.sort(np.concatenate((evid_s, evid_e, evid_se)))  # the sorted index array of the events which show overlaping times with the detected event
                            assert(len(evid) > 1)
                            event_info[station_name]['S']['starttime'][evid[0]] = copy.deepcopy(min(np.min(np.array(event_info[station_name]['S']['starttime'])[evid]), temp_startime))
                            event_info[station_name]['S']['endtime'][evid[0]] = copy.deepcopy(max(np.max(np.array(event_info[station_name]['S']['endtime'])[evid]), temp_endtime))
                            xxid = np.argmax(np.array(event_info[station_name]['S']['maxprob'])[evid])
                            if event_info[station_name]['S']['maxprob'][evid[xxid]] < temp_maxprob:
                                event_info[station_name]['S']['maxprob'][evid[0]] = copy.deepcopy(temp_maxprob)
                                event_info[station_name]['S']['mxptime'][evid[0]] = copy.deepcopy(temp_mxptime)
                                event_info[station_name]['S']['sgname'][evid[0]] = copy.deepcopy(idsg)
                            else:
                                event_info[station_name]['S']['maxprob'][evid[0]] = copy.deepcopy(event_info[station_name]['S']['maxprob'][evid[xxid]])
                                event_info[station_name]['S']['mxptime'][evid[0]] = copy.deepcopy(event_info[station_name]['S']['mxptime'][evid[xxid]])
                                event_info[station_name]['S']['sgname'][evid[0]] = copy.deepcopy(event_info[station_name]['S']['sgname'][evid[xxid]])
                            for jjj in evid[-1:0:-1]:
                                # delete the other events
                                del event_info[station_name]['S']['starttime'][jjj]
                                del event_info[station_name]['S']['endtime'][jjj]
                                del event_info[station_name]['S']['maxprob'][jjj]
                                del event_info[station_name]['S']['mxptime'][jjj]
                                del event_info[station_name]['S']['sgname'][jjj]
                            del evid, xxid
                            
                        else:
                            # do not have time overlaping with any event, directly insert into the event list
                            assert(len(evid_s)==0 and len(evid_e)==0 and len(evid_se)==0 and len(evid_in) ==0)
                            insertid = np.flatnonzero(np.array(event_info[station_name]['S']['starttime']) > temp_startime)
                            if (len(insertid) > 0):
                                event_info[station_name]['S']['starttime'].insert(insertid[0], copy.deepcopy(temp_startime))
                                event_info[station_name]['S']['endtime'].insert(insertid[0], copy.deepcopy(temp_endtime))
                                event_info[station_name]['S']['maxprob'].insert(insertid[0], copy.deepcopy(temp_maxprob))
                                event_info[station_name]['S']['mxptime'].insert(insertid[0], copy.deepcopy(temp_mxptime))
                                event_info[station_name]['S']['sgname'].insert(insertid[0], copy.deepcopy(idsg))
                            else:
                                event_info[station_name]['S']['starttime'].append(copy.deepcopy(temp_startime))
                                event_info[station_name]['S']['endtime'].append(copy.deepcopy(temp_endtime))
                                event_info[station_name]['S']['maxprob'].append(copy.deepcopy(temp_maxprob))
                                event_info[station_name]['S']['mxptime'].append(copy.deepcopy(temp_mxptime))
                                event_info[station_name]['S']['sgname'].append(copy.deepcopy(idsg))
                            del insertid
                        del evid_s, evid_e, evid_se, evid_in
                    else:
                        # no detected events yet, append the detected event to the empty event list directly
                        event_info[station_name]['S']['starttime'].append(copy.deepcopy(temp_startime))
                        event_info[station_name]['S']['endtime'].append(copy.deepcopy(temp_endtime))
                        event_info[station_name]['S']['maxprob'].append(copy.deepcopy(temp_maxprob))
                        event_info[station_name]['S']['mxptime'].append(copy.deepcopy(temp_mxptime))
                        event_info[station_name]['S']['sgname'].append(copy.deepcopy(idsg))
                    
                    del temp_startime, temp_endtime, temp_maxprob, temp_mxptime, start_did, end_did
                    assert(event_info[station_name]['S']['mxptime'][-1] >= event_info[station_name]['S']['starttime'][-1])
                    assert(event_info[station_name]['S']['mxptime'][-1] <= event_info[station_name]['S']['endtime'][-1])
            del epindx 
            
            del pbdata, pbtime
        assert(len(event_info[station_name]['P']['starttime']) == len(event_info[station_name]['P']['endtime']))
        assert(len(event_info[station_name]['P']['endtime']) == len(event_info[station_name]['P']['maxprob']))
        assert(len(event_info[station_name]['P']['maxprob']) == len(event_info[station_name]['P']['mxptime']))
        assert(len(event_info[station_name]['P']['mxptime']) == len(event_info[station_name]['P']['sgname']))
        assert(len(event_info[station_name]['S']['starttime']) == len(event_info[station_name]['S']['endtime']))
        assert(len(event_info[station_name]['S']['endtime']) == len(event_info[station_name]['S']['maxprob']))
        assert(len(event_info[station_name]['S']['maxprob']) == len(event_info[station_name]['S']['mxptime']))
        assert(len(event_info[station_name]['S']['mxptime']) == len(event_info[station_name]['S']['sgname']))
        del station_name, pbfile, pbdf, dsg_name, dsg_starttime, dsg_endtime 
    
    gc.collect()
    return event_info


def arrayeventdetect(event_info, twind_srch, twlex=None, nsta_thrd=3):
    """
    This function is used to detect locatable event accross the whole arrary.
    Parameters
    ----------
    event_info : dict
        containing the detected event information at each station. Check 
        'eqt_eventdetectfprob' for detailed information.
    twind_srch : float
        time window length in second where events will be searched in this range.
        How to determine this parameter:
        Conservative estimation: maximum P-S traveltime difference between 
        different stations for the whole imaging area.
    twlex : float, optional
        time window length in second for extending the output time range, 
        usually set to be 1-2 second. If None, then determine automatically 
        according to 'twind_srch'.
    nsta_thrd : int, optional
        minimal number of stations triggered during the specified time period ('twind_srch'), 
        If there are more triggered stations than this threshold, the algrithem
        determines there is an event in the current searched time period, then
        it will start to ouput probapility data of different stations to the 
        defined output directory. Each event will have a unique folder name 
        according to the starttime of its data segment.
        The default is 3.

    Returns
    -------
    Obspy trace data outputted in MSEED format in the defined output directory.

    """
    
    stations = list(event_info.keys())  # get all station names
    N_stations = len(event_info)  # total number of stations
    
    # get the earliest starttime and the latest endtime of all detections for each station
    etime_sta = []  # the earliest starttime of all detections for each station
    ltime_sta = []  # the latest endtime of all detections for each station
    for sta in stations:
        etime_sta.append(copy.deepcopy(min(min(event_info[sta]['P']['starttime']), min(event_info[sta]['S']['starttime']))))
        ltime_sta.append(copy.deepcopy(max(max(event_info[sta]['P']['endtime']), max(event_info[sta]['S']['endtime']))))    
    assert(len(etime_sta) == N_stations)
    assert(len(ltime_sta) == N_stations)
    time_min = copy.deepcopy(min(etime_sta))  # the earliest starttime of all events, used to set the start point of the searched time range
    time_max = copy.deepcopy(max(ltime_sta))  # the latest endtime of all events, used to limit the searched time range
    del etime_sta, ltime_sta
        
    # scan the whole array for locatable events
    srchtime_start = copy.deepcopy(time_min)  # use the earliest starttime of all events as the start time for searching
    while srchtime_start <= time_max:
        srchtime_end = copy.deepcopy(srchtime_start + datetime.timedelta(seconds=twind_srch))  # get/update the end of the searched time range
        
        # initialize parameters
        nsta_trig = 0  # total number of stations triggered
        etime_sta = []  # for storing the earliest starttime of all the remaining detections after the previous round of searching
        
        for ista in stations:
            # loop over each station to search for events
            Pevidx = np.flatnonzero((np.array(event_info[ista]['P']['mxptime']) >= srchtime_start) & (np.array(event_info[ista]['P']['mxptime']) <= srchtime_end))  # index for P detections that are in the current searched time range
            Sevidx = np.flatnonzero((np.array(event_info[ista]['S']['mxptime']) >= srchtime_start) & (np.array(event_info[ista]['S']['mxptime']) <= srchtime_end))  # index for S detections that are in the current searched time range
            
            if (len(Pevidx) > 0) and (len(Sevidx) > 0):
                # have both P and S detection in this time range
                nsta_trig = nsta_trig + 1  # update total number of stations triggered
                mxpeid = np.argmax(np.array(event_info[ista]['P']['maxprob'])[Pevidx])
                
                
            elif (len(Pevidx) > 0) and (len(Sevidx) == 0):
                # only have P detection in this time range
                nsta_trig = nsta_trig + 1  # update total number of stations triggered
                
            elif (len(Pevidx) == 0) and (len(Sevidx) > 0):
                # only have S detection in this time range
                nsta_trig = nsta_trig + 1  # update total number of stations triggered
                
 
        if (nsta_trig >= nsta_thrd):
            # have enough triggered stations
            
    
    
        srchtime_start =  # update the start of the searched time range
        del nsta_trig, srchtime_start
        
    return




